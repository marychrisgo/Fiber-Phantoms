{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generate_fibers as gf\n",
    "import perform_ASTRA as tomo\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Only able to place 29 fibers after 10000 attempts.\n",
      "Total processing time: 204.4698567390442 seconds\n",
      "Warning: Only able to place 26 fibers after 10000 attempts.\n",
      "Total processing time: 421.8956274986267 seconds\n",
      "Warning: Only able to place 17 fibers after 10000 attempts.\n",
      "Total processing time: 637.4981167316437 seconds\n",
      "Warning: Only able to place 22 fibers after 10000 attempts.\n",
      "Total processing time: 857.5083334445953 seconds\n",
      "Warning: Only able to place 13 fibers after 10000 attempts.\n",
      "Total processing time: 1075.424712896347 seconds\n",
      "Warning: Only able to place 27 fibers after 10000 attempts.\n",
      "Total processing time: 1291.567173242569 seconds\n",
      "Warning: Only able to place 30 fibers after 10000 attempts.\n",
      "Total processing time: 1507.5217757225037 seconds\n",
      "Warning: Only able to place 23 fibers after 10000 attempts.\n",
      "Total processing time: 1724.336442232132 seconds\n",
      "Warning: Only able to place 22 fibers after 10000 attempts.\n",
      "Total processing time: 1940.0048670768738 seconds\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    start_time = time.time()\n",
    "    with open(\"parameters.json\", \"r\") as file:\n",
    "        params = json.load(file)\n",
    "    \n",
    "    for i in range(91, 91+params[\"num_volumes\"]):\n",
    "        volume = np.zeros(params[\"volume_dimensions\"])\n",
    "        random_seed = params[\"random_seed\"] + i  # diff seed for each volume\n",
    "\n",
    "        gf.generate_and_count_fibers(volume, params[\"num_fibers\"], params[\"mode\"], params[\"pipe_radius\"])\n",
    "\n",
    "        volume_filename = f\"fiber_curved_volume_{i}.nii\"\n",
    "        gf.save_as_nifti(volume, volume_filename)\n",
    "\n",
    "        original_recon, noisy_recon = tomo.perform_tomography(\n",
    "            volume, params[\"volume_dimensions\"], params[\"num_angles\"], params[\"geometry_type\"],\n",
    "            params[\"det_width_u\"], params[\"det_width_v\"], params[\"det_count_x\"],\n",
    "            params[\"det_count_y\"], params[\"i0\"], params[\"gamma\"], params[\"algorithm\"], params[\"show_plots\"]\n",
    "        )\n",
    "\n",
    "        gf.save_as_nifti(original_recon, f\"original_reconstruction_{i}.nii\")\n",
    "        gf.save_as_nifti(noisy_recon, f\"noisy_reconstruction_{i}.nii\")\n",
    "\n",
    "        with h5py.File(f\"volume_and_reconstruction_{i}.hdf5\", \"w\") as h5f:\n",
    "            for key, value in params.items():\n",
    "                h5f.attrs[key] = str(value)\n",
    "            h5f.attrs[\"random_seed\"] = str(random_seed)\n",
    "\n",
    "        end_time = time.time() \n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f\"Total processing time: {elapsed_time} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata:\n",
      "algorithm: SIRT3D_CUDA\n",
      "det_count_x: 512\n",
      "det_count_y: 768\n",
      "det_width_u: 1.0\n",
      "det_width_v: 1.0\n",
      "gamma: 0.005\n",
      "geometry_type: parallel3d\n",
      "i0: 200\n",
      "mode: straight\n",
      "num_angles: 180\n",
      "num_fibers: 200\n",
      "num_volumes: 50\n",
      "pipe_radius: 250\n",
      "random_seed: 42\n",
      "show_plots: True\n",
      "volume_dimensions: [512, 512, 512]\n"
     ]
    }
   ],
   "source": [
    "# for checking \n",
    "\n",
    "file_path = 'volume_and_reconstruction_0.hdf5'\n",
    "\n",
    "def read_hdf5(file_path):\n",
    "    with h5py.File(file_path, \"r\") as file:\n",
    "        print(\"Metadata:\")\n",
    "        for attr_name, attr_value in file.attrs.items():\n",
    "            print(f\"{attr_name}: {attr_value}\")\n",
    "\n",
    "read_hdf5(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
